{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal, stats\n",
    "from scipy.stats import pointbiserialr\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "import mrmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_nr_asarrays(column_name, full_dataframe):\n",
    "    responders = np.array(full_dataframe.loc[full_dataframe[\"response\"] == 1, column_name])\n",
    "    non_responders = np.array(full_dataframe.loc[full_dataframe[\"response\"] == 0, column_name])\n",
    "    return responders, non_responders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pd.read_csv('response.csv', sep=';') # Read the response data\n",
    "features = pd.read_csv('surrogate_18042022.csv', index_col=0) # Read the features dataframe\n",
    "\n",
    "# To create columns with the ration among the features on AWAKE/SLEEP state\n",
    "for measure in ['wPLI', 'PDC', 'DTF']:\n",
    "    if measure == 'wPLI':\n",
    "        for f_band in ['delta', 'theta', 'alpha', 'beta', 'broadband']:\n",
    "            features[f'{measure}_{f_band}_ASRATIO_MEAN_SYNCH'] = features[f'{measure}_{f_band}_AWAKE_MEAN_SYNCH'].div(features[f'{measure}_{f_band}_SLEEP_MEAN_SYNCH'])\n",
    "    else:\n",
    "        for f_band in ['delta', 'theta', 'alpha', 'beta', 'broadband']:\n",
    "            for graph_measures in ['GE', 'GRC', 'MOD', 'DA', 'AVGCC']:\n",
    "                features[f'{measure}_{f_band}_ASRATIO_{graph_measures}'] = features[f'{measure}_{f_band}_AWAKE_{graph_measures}'].div(features[f'{measure}_{f_band}_SLEEP_{graph_measures}'])\n",
    "\n",
    "full_df = pd.merge(features, response, on='patient', how='outer') # Join the two dataframes\n",
    "full_df = full_df.dropna() # Drop the NaN values\n",
    "full_df.loc[full_df[\"response\"] == \"RP\", \"response\"] = 1\n",
    "full_df.loc[full_df[\"response\"] == \"PR\", \"response\"] = 1\n",
    "full_df.loc[full_df[\"response\"] == \"R\", \"response\"]  = 1\n",
    "full_df.loc[full_df[\"response\"] == \"NR\", \"response\"] = 0\n",
    "\n",
    "full_df.drop(columns=['patient'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=full_df.sample(n=30, random_state=42)\n",
    "test=full_df.drop(train.index)\n",
    "full_df = train.sort_index().copy()\n",
    "test_df = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='response', ylabel='count'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(full_df['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features selection\n",
    "\n",
    "Here we perform the feature selection for the methods. The CFS is executed once and it has a fixed set for all the methods, while the MrMr and the SFS should be executed for all the methods.\n",
    "\n",
    "CFS:\n",
    "https://johfischer.com/2021/08/06/correlation-based-feature-selection-in-python-from-scratch/#:~:text=The%20correlation%2Dbased%20feature%20selection%20(CFS)%20method%20is%20a,the%20name%20already%20suggest%3A%20correlations.\n",
    "\n",
    "Maximum relevance Minimum redundancy (MrMr):\n",
    "https://github.com/smazzanti/mrmr\n",
    "\n",
    "https://towardsdatascience.com/mrmr-explained-exactly-how-you-wished-someone-explained-to-you-9cf4ed27458b\n",
    "\n",
    "Sequential Feature Selection (SFS):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation based feature selection (CFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pointbiserialr\n",
    "from math import sqrt\n",
    "\n",
    "def getMerit(subset, label, df):\n",
    "    k = len(subset)\n",
    "\n",
    "    # average feature-class correlation\n",
    "    rcf_all = []\n",
    "    for feature in subset:\n",
    "        coeff = pointbiserialr( df[label], df[feature] )\n",
    "        rcf_all.append( abs( coeff.correlation ) )\n",
    "    rcf = np.mean( rcf_all )\n",
    "\n",
    "    # average feature-feature correlation\n",
    "    corr = df[subset].corr()\n",
    "    corr.values[np.tril_indices_from(corr.values)] = np.nan\n",
    "    corr = abs(corr)\n",
    "    rff = corr.unstack().mean()\n",
    "\n",
    "    return (k * rcf) / sqrt(k + k * (k-1) * rff)\n",
    "\n",
    "class PriorityQueue:\n",
    "    def  __init__(self):\n",
    "        self.queue = []\n",
    "\n",
    "    def isEmpty(self):\n",
    "        return len(self.queue) == 0\n",
    "    \n",
    "    def push(self, item, priority):\n",
    "        \"\"\"\n",
    "        item already in priority queue with smaller priority:\n",
    "        -> update its priority\n",
    "        item already in priority queue with higher priority:\n",
    "        -> do nothing\n",
    "        if item not in priority queue:\n",
    "        -> push it\n",
    "        \"\"\"\n",
    "        for index, (i, p) in enumerate(self.queue):\n",
    "            if (set(i) == set(item)):\n",
    "                if (p >= priority):\n",
    "                    break\n",
    "                del self.queue[index]\n",
    "                self.queue.append( (item, priority) )\n",
    "                break\n",
    "        else:\n",
    "            self.queue.append( (item, priority) )\n",
    "        \n",
    "    def pop(self):\n",
    "        # return item with highest priority and remove it from queue\n",
    "        max_idx = 0\n",
    "        for index, (i, p) in enumerate(self.queue):\n",
    "            if (self.queue[max_idx][1] < p):\n",
    "                max_idx = index\n",
    "        (item, priority) = self.queue[max_idx]\n",
    "        del self.queue[max_idx]\n",
    "        return (item, priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature PDC_beta_SLEEP_GE with merit 0.4319\n"
     ]
    }
   ],
   "source": [
    "label = 'response'\n",
    "\n",
    "# list with feature names (V1, V2, V3, ...)\n",
    "features = full_df.columns.tolist()\n",
    "features.remove(label)\n",
    "\n",
    "# First we get the initial feature\n",
    "best_value = -1\n",
    "best_feature = ''\n",
    "for feature in features:\n",
    "    coeff = pointbiserialr(full_df[label], full_df[feature])\n",
    "    abs_coeff = abs( coeff.correlation )\n",
    "    if abs_coeff > best_value:\n",
    "        best_value = abs_coeff\n",
    "        best_feature = feature\n",
    "\n",
    "print(\"Feature %s with merit %.4f\"%(best_feature, best_value))\n",
    "\n",
    "# Then we initialize the queue and push the best feature into it\n",
    "# initialize queue\n",
    "queue = PriorityQueue()\n",
    "\n",
    "# push first tuple (subset, merit)\n",
    "queue.push([best_feature], best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for visited nodes\n",
    "visited = []\n",
    "\n",
    "# counter for backtracks\n",
    "n_backtrack = 0\n",
    "\n",
    "# limit of backtracks\n",
    "max_backtrack = 5\n",
    "\n",
    "\n",
    "# repeat until queue is empty\n",
    "# or the maximum number of backtracks is reached\n",
    "while not queue.isEmpty():\n",
    "    # get element of queue with highest merit\n",
    "    subset, priority = queue.pop()\n",
    "    \n",
    "    # check whether the priority of this subset\n",
    "    # is higher than the current best subset\n",
    "    if (priority < best_value):\n",
    "        n_backtrack += 1\n",
    "    else:\n",
    "        best_value = priority\n",
    "        best_subset = subset\n",
    "\n",
    "    # goal condition\n",
    "    if (n_backtrack == max_backtrack):\n",
    "        break\n",
    "    \n",
    "    # iterate through all features and look of one can\n",
    "    # increase the merit\n",
    "    for feature in features:\n",
    "        temp_subset = subset + [feature]\n",
    "        \n",
    "        # check if this subset has already been evaluated\n",
    "        for node in visited:\n",
    "            if (set(node) == set(temp_subset)):\n",
    "                break\n",
    "        # if not, ...\n",
    "        else:\n",
    "            # ... mark it as visited\n",
    "            visited.append( temp_subset )\n",
    "            # ... compute merit\n",
    "            merit = getMerit(temp_subset, label, full_df)\n",
    "            # and push it to the queue\n",
    "            queue.push(temp_subset, merit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_subset_cbfs = best_subset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Maximum relevance minimum redundancy (MrMr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MrMr_features_number_test(model, X, Y, features_n_end, cv_folds=10):\n",
    "    \"\"\"\n",
    "    Given a ML model this function returns the score of the subsets obtained through the MrMr\n",
    "    feature selection.\n",
    "    Input:\n",
    "        model (sk-learn ML model) : the ML model;\n",
    "        X (Pandas DataFrame) : Pandas DataFrame containing the features without the labels;\n",
    "        Y (Pandas Series) : Pandas Series (column) containing the labels for each sample;\n",
    "        features_n_end (int) : maximum number of features to test;\n",
    "    Output:\n",
    "        results (Pandas DataFrame) : Pandas DataFrame containing the subset and the score associated to it.\n",
    "    \"\"\"\n",
    "    feature_names = X.columns\n",
    "    results = {}\n",
    "    results['features'], results['features_len'], results['cv_acc'] = [], [], []\n",
    "    \n",
    "    selected_features = mrmr.mrmr_classif(X=X, y=Y, K=features_n_end, show_progress=False)\n",
    "    \n",
    "    Y_ = Y.to_numpy(dtype='int')\n",
    "    \n",
    "    for n_features in tqdm(range(1, features_n_end)):\n",
    "        subset_features = selected_features[0:n_features]\n",
    "        \n",
    "        X_ = X[subset_features].to_numpy()\n",
    "        \n",
    "        scores_subset = cross_val_score(model, X_, Y_, cv=cv_folds)\n",
    "        best_score = np.mean(scores_subset)\n",
    "        \n",
    "        results['features'].append(subset_features)\n",
    "        results['features_len'].append(n_features)\n",
    "        results['cv_acc'].append(best_score)\n",
    "    results = pd.DataFrame(results)\n",
    "    return results.sort_values(by=['cv_acc', 'features_len'], ascending=[False, True], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "def SFS_features_number_test(model, X, Y, features_n_end, cv_folds=10):\n",
    "    \"\"\"\n",
    "    Given a ML model this function returns the score of the subsets obtained through the Sequential\n",
    "    Feature Selection.\n",
    "    Input:\n",
    "        model (sk-learn ML model) : the ML model;\n",
    "        X (Pandas DataFrame) : Pandas DataFrame containing the features without the labels;\n",
    "        Y (Pandas Series) : Pandas Series (column) containing the labels for each sample;\n",
    "        features_n_end (int) : maximum number of features to test;\n",
    "    Output:\n",
    "        results (Pandas DataFrame) : Pandas DataFrame containing the subset and the score associated to it.\n",
    "    \"\"\"\n",
    "    feature_names = X.columns\n",
    "    results = {}\n",
    "    results['features'], results['features_len'], results['cv_acc'] = [], [], []\n",
    "    sfs_forward = SequentialFeatureSelector(model, n_features_to_select=features_n_end, direction=\"forward\").fit(X, Y)\n",
    "    selected_features = list(feature_names[sfs_forward.get_support()])\n",
    "    Y_ = Y.to_numpy(dtype='int')\n",
    "    for n_features in tqdm(range(1, features_n_end)):\n",
    "        subset_features = selected_features[0:n_features]\n",
    "        \n",
    "        X_ = X[subset_features].to_numpy()\n",
    "        \n",
    "        scores_subset = cross_val_score(model, X_, Y_, cv=cv_folds)\n",
    "        best_score = np.mean(scores_subset)\n",
    "        \n",
    "        results['features'].append(subset_features)\n",
    "        results['features_len'].append(n_features)\n",
    "        results['cv_acc'].append(best_score)\n",
    "    results = pd.DataFrame(results)\n",
    "    return results.sort_values(by=['cv_acc', 'features_len'], ascending=[False, True], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection and tuning\n",
    "\n",
    "On this stage we select the best model, but first we find the best hyperparameters combination for each set of features selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 66.39it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 66.84it/s]\n"
     ]
    }
   ],
   "source": [
    "X = full_df.drop(columns=['response'], inplace=False)\n",
    "Y = full_df['response']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = SVC(kernel='linear')\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "features_cbfs = features_subset_cbfs.copy() \n",
    "\n",
    "results_mrmr = MrMr_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_mrmr = results_mrmr.iloc[0]['features']\n",
    "\n",
    "results_sfs = SFS_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_sfs = results_sfs.iloc[0]['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best CBFS (with 16 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model', SVC(C=10, kernel='linear', tol=0.1))]), with a validation acc of: 0.8666666666666666\n",
      "The best MRMR (with 8 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model', SVC(C=1, kernel='linear', tol=0.1))]), with a validation acc of: 0.8000000000000002\n",
      "The best SFS (with 12 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model', SVC(C=10, kernel='linear', tol=0.1))]), with a validation acc of: 0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "Y_ = Y.to_numpy(dtype='int')\n",
    "X_cbfs, X_mrmr, X_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "\n",
    "cv_folds = 6\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = SVC(kernel='linear')\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "param_grid = [\n",
    "  {'ml_model__C': [1, 10, 100, 1000], 'ml_model__kernel': ['linear'], 'ml_model__tol': [0.1, 0.01, 0.001, 0.0001, 0.00001]},\n",
    " ]\n",
    "param_lookup_cbfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_cbfs.fit(X_cbfs, Y_)\n",
    "best_model_cbfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "param_lookup_mrmr = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_mrmr.fit(X_mrmr, Y_)\n",
    "best_model_mrmr = param_lookup_mrmr.best_estimator_\n",
    "\n",
    "param_lookup_sfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_sfs.fit(X_sfs, Y_)\n",
    "best_model_sfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "scores_subset_cbfs = cross_val_score(best_model_cbfs, X_cbfs, Y_, cv=cv_folds)\n",
    "best_score_cbfs = np.mean(scores_subset_cbfs)\n",
    "\n",
    "scores_subset_mrmr = cross_val_score(best_model_mrmr, X_mrmr, Y_, cv=cv_folds)\n",
    "best_score_mrmr = np.mean(scores_subset_mrmr)\n",
    "\n",
    "scores_subset_sfs = cross_val_score(best_model_sfs, X_sfs, Y_, cv=cv_folds)\n",
    "best_score_sfs = np.mean(scores_subset_sfs)\n",
    "\n",
    "print(f'The best CBFS (with {len(features_cbfs)} features) model found is {best_model_cbfs}, with a validation acc of: {best_score_cbfs}')\n",
    "print(f'The best MRMR (with {len(features_mrmr)} features) model found is {best_model_mrmr}, with a validation acc of: {best_score_mrmr}')\n",
    "print(f'The best SFS (with {len(features_sfs)} features) model found is {best_model_sfs}, with a validation acc of: {best_score_sfs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained for the CBFS model is: 0.5714285714285714\n",
      "The test accuracy obtained for the MrMr model is: 0.5714285714285714\n",
      "The test accuracy obtained for the SFS model is: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(columns=['response'], inplace=False)\n",
    "Y_test = test_df['response'].to_numpy(dtype='int')\n",
    "\n",
    "X_train_cbfs, X_train_mrmr, X_train_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "Y_train = Y.to_numpy(dtype='int')\n",
    "\n",
    "best_model_cbfs = clone(best_model_cbfs)\n",
    "best_model_mrmr = clone(best_model_mrmr)\n",
    "best_model_sfs = clone(best_model_sfs)\n",
    "\n",
    "best_model_cbfs.fit(X_train_cbfs, Y_train)\n",
    "best_model_mrmr.fit(X_train_mrmr, Y_train)\n",
    "best_model_sfs.fit(X_train_sfs, Y_train)\n",
    "\n",
    "Y_pred_cbfs = best_model_cbfs.predict(X_test[features_cbfs].to_numpy())\n",
    "Y_pred_mrmr = best_model_mrmr.predict(X_test[features_mrmr].to_numpy())\n",
    "Y_pred_sfs = best_model_sfs.predict(X_test[features_sfs].to_numpy())\n",
    "\n",
    "cbfs_test_acc = accuracy_score(Y_test, Y_pred_cbfs)\n",
    "mrmr_test_acc = accuracy_score(Y_test, Y_pred_mrmr)\n",
    "sfs_test_acc = accuracy_score(Y_test, Y_pred_sfs)\n",
    "\n",
    "print(f'The test accuracy obtained for the CBFS model is: {cbfs_test_acc}')\n",
    "print(f'The test accuracy obtained for the MrMr model is: {mrmr_test_acc}')\n",
    "print(f'The test accuracy obtained for the SFS model is: {sfs_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 57.38it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 66.38it/s]\n"
     ]
    }
   ],
   "source": [
    "X = full_df.drop(columns=['response'], inplace=False)\n",
    "Y = full_df['response']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = SVC(kernel='rbf')\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "features_cbfs = features_subset_cbfs.copy() \n",
    "\n",
    "results_mrmr = MrMr_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_mrmr = results_mrmr.iloc[0]['features']\n",
    "\n",
    "results_sfs = SFS_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_sfs = results_sfs.iloc[0]['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best CBFS (with 16 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model', SVC(C=1000, gamma=0.01, tol=0.01))]), with a validation acc of: 0.8666666666666666\n",
      "The best MRMR (with 4 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model', SVC(C=1000, gamma=0.1, tol=0.1))]), with a validation acc of: 0.8666666666666666\n",
      "The best SFS (with 6 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model', SVC(C=1000, gamma=0.01, tol=0.01))]), with a validation acc of: 0.5666666666666668\n"
     ]
    }
   ],
   "source": [
    "Y_ = Y.to_numpy(dtype='int')\n",
    "X_cbfs, X_mrmr, X_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "\n",
    "cv_folds = 6\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = SVC()\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "param_grid = [\n",
    "  {'ml_model__C': [1, 10, 100, 1000], 'ml_model__gamma': [0.1, 0.01, 0.001, 0.0001, 'auto', 'scale'], 'ml_model__kernel': ['rbf'],\n",
    "  'ml_model__tol': [0.1, 0.01, 0.001, 0.0001, 0.00001]},\n",
    " ]\n",
    "param_lookup_cbfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_cbfs.fit(X_cbfs, Y_)\n",
    "best_model_cbfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "param_lookup_mrmr = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_mrmr.fit(X_mrmr, Y_)\n",
    "best_model_mrmr = param_lookup_mrmr.best_estimator_\n",
    "\n",
    "param_lookup_sfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_sfs.fit(X_sfs, Y_)\n",
    "best_model_sfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "scores_subset_cbfs = cross_val_score(best_model_cbfs, X_cbfs, Y_, cv=cv_folds)\n",
    "best_score_cbfs = np.mean(scores_subset_cbfs)\n",
    "\n",
    "scores_subset_mrmr = cross_val_score(best_model_mrmr, X_mrmr, Y_, cv=cv_folds)\n",
    "best_score_mrmr = np.mean(scores_subset_mrmr)\n",
    "\n",
    "scores_subset_sfs = cross_val_score(best_model_sfs, X_sfs, Y_, cv=cv_folds)\n",
    "best_score_sfs = np.mean(scores_subset_sfs)\n",
    "\n",
    "print(f'The best CBFS (with {len(features_cbfs)} features) model found is {best_model_cbfs}, with a validation acc of: {best_score_cbfs}')\n",
    "print(f'The best MRMR (with {len(features_mrmr)} features) model found is {best_model_mrmr}, with a validation acc of: {best_score_mrmr}')\n",
    "print(f'The best SFS (with {len(features_sfs)} features) model found is {best_model_sfs}, with a validation acc of: {best_score_sfs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained for the CBFS model is: 0.7142857142857143\n",
      "The test accuracy obtained for the MrMr model is: 0.5714285714285714\n",
      "The test accuracy obtained for the SFS model is: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(columns=['response'], inplace=False)\n",
    "Y_test = test_df['response'].to_numpy(dtype='int')\n",
    "\n",
    "X_train_cbfs, X_train_mrmr, X_train_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "Y_train = Y.to_numpy(dtype='int')\n",
    "\n",
    "best_model_cbfs = clone(best_model_cbfs)\n",
    "best_model_mrmr = clone(best_model_mrmr)\n",
    "best_model_sfs = clone(best_model_sfs)\n",
    "\n",
    "best_model_cbfs.fit(X_train_cbfs, Y_train)\n",
    "best_model_mrmr.fit(X_train_mrmr, Y_train)\n",
    "best_model_sfs.fit(X_train_sfs, Y_train)\n",
    "\n",
    "Y_pred_cbfs = best_model_cbfs.predict(X_test[features_cbfs].to_numpy())\n",
    "Y_pred_mrmr = best_model_mrmr.predict(X_test[features_mrmr].to_numpy())\n",
    "Y_pred_sfs = best_model_sfs.predict(X_test[features_sfs].to_numpy())\n",
    "\n",
    "cbfs_test_acc = accuracy_score(Y_test, Y_pred_cbfs)\n",
    "mrmr_test_acc = accuracy_score(Y_test, Y_pred_mrmr)\n",
    "sfs_test_acc = accuracy_score(Y_test, Y_pred_sfs)\n",
    "\n",
    "print(f'The test accuracy obtained for the CBFS model is: {cbfs_test_acc}')\n",
    "print(f'The test accuracy obtained for the MrMr model is: {mrmr_test_acc}')\n",
    "print(f'The test accuracy obtained for the SFS model is: {sfs_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 63.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 67.80it/s]\n"
     ]
    }
   ],
   "source": [
    "X = full_df.drop(columns=['response'], inplace=False)\n",
    "Y = full_df['response']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = SVC(kernel='poly')\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "features_cbfs = features_subset_cbfs.copy() \n",
    "\n",
    "results_mrmr = MrMr_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_mrmr = results_mrmr.iloc[0]['features']\n",
    "\n",
    "results_sfs = SFS_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_sfs = results_sfs.iloc[0]['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best CBFS (with 16 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model', SVC(C=10, gamma=0.1, kernel='poly', tol=0.1))]), with a validation acc of: 0.7999999999999999\n",
      "The best MRMR (with 5 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model', SVC(C=1, kernel='poly', tol=0.1))]), with a validation acc of: 0.8999999999999999\n",
      "The best SFS (with 15 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model', SVC(C=10, gamma=0.1, kernel='poly', tol=0.1))]), with a validation acc of: 0.6\n"
     ]
    }
   ],
   "source": [
    "Y_ = Y.to_numpy(dtype='int')\n",
    "X_cbfs, X_mrmr, X_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "\n",
    "cv_folds = 6\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = SVC(kernel='poly')\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "param_grid = [\n",
    "  {'ml_model__C': [1, 10, 100, 1000], 'ml_model__gamma': [0.1, 0.01, 0.001, 0.0001, 'auto', 'scale'], 'ml_model__kernel': ['poly'],\n",
    "  'ml_model__tol': [0.1, 0.01, 0.001, 0.0001, 0.00001]},\n",
    " ]\n",
    "param_lookup_cbfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_cbfs.fit(X_cbfs, Y_)\n",
    "best_model_cbfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "param_lookup_mrmr = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_mrmr.fit(X_mrmr, Y_)\n",
    "best_model_mrmr = param_lookup_mrmr.best_estimator_\n",
    "\n",
    "param_lookup_sfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_sfs.fit(X_sfs, Y_)\n",
    "best_model_sfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "scores_subset_cbfs = cross_val_score(best_model_cbfs, X_cbfs, Y_, cv=cv_folds)\n",
    "best_score_cbfs = np.mean(scores_subset_cbfs)\n",
    "\n",
    "scores_subset_mrmr = cross_val_score(best_model_mrmr, X_mrmr, Y_, cv=cv_folds)\n",
    "best_score_mrmr = np.mean(scores_subset_mrmr)\n",
    "\n",
    "scores_subset_sfs = cross_val_score(best_model_sfs, X_sfs, Y_, cv=cv_folds)\n",
    "best_score_sfs = np.mean(scores_subset_sfs)\n",
    "\n",
    "print(f'The best CBFS (with {len(features_cbfs)} features) model found is {best_model_cbfs}, with a validation acc of: {best_score_cbfs}')\n",
    "print(f'The best MRMR (with {len(features_mrmr)} features) model found is {best_model_mrmr}, with a validation acc of: {best_score_mrmr}')\n",
    "print(f'The best SFS (with {len(features_sfs)} features) model found is {best_model_sfs}, with a validation acc of: {best_score_sfs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained for the CBFS model is: 0.7142857142857143\n",
      "The test accuracy obtained for the MrMr model is: 0.7142857142857143\n",
      "The test accuracy obtained for the SFS model is: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(columns=['response'], inplace=False)\n",
    "Y_test = test_df['response'].to_numpy(dtype='int')\n",
    "\n",
    "X_train_cbfs, X_train_mrmr, X_train_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "Y_train = Y.to_numpy(dtype='int')\n",
    "\n",
    "best_model_cbfs = clone(best_model_cbfs)\n",
    "best_model_mrmr = clone(best_model_mrmr)\n",
    "best_model_sfs = clone(best_model_sfs)\n",
    "\n",
    "best_model_cbfs.fit(X_train_cbfs, Y_train)\n",
    "best_model_mrmr.fit(X_train_mrmr, Y_train)\n",
    "best_model_sfs.fit(X_train_sfs, Y_train)\n",
    "\n",
    "Y_pred_cbfs = best_model_cbfs.predict(X_test[features_cbfs].to_numpy())\n",
    "Y_pred_mrmr = best_model_mrmr.predict(X_test[features_mrmr].to_numpy())\n",
    "Y_pred_sfs = best_model_sfs.predict(X_test[features_sfs].to_numpy())\n",
    "\n",
    "cbfs_test_acc = accuracy_score(Y_test, Y_pred_cbfs)\n",
    "mrmr_test_acc = accuracy_score(Y_test, Y_pred_mrmr)\n",
    "sfs_test_acc = accuracy_score(Y_test, Y_pred_sfs)\n",
    "\n",
    "print(f'The test accuracy obtained for the CBFS model is: {cbfs_test_acc}')\n",
    "print(f'The test accuracy obtained for the MrMr model is: {mrmr_test_acc}')\n",
    "print(f'The test accuracy obtained for the SFS model is: {sfs_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 37.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 37.74it/s]\n"
     ]
    }
   ],
   "source": [
    "X = full_df.drop(columns=['response'], inplace=False)\n",
    "Y = full_df['response']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = GaussianProcessClassifier()\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "features_cbfs = features_subset_cbfs.copy() \n",
    "\n",
    "results_mrmr = MrMr_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_mrmr = results_mrmr.iloc[0]['features']\n",
    "\n",
    "results_sfs = SFS_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_sfs = results_sfs.iloc[0]['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best CBFS (with 16 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model',\n",
      "                 GaussianProcessClassifier(kernel=RBF(length_scale=1) + WhiteKernel(noise_level=1)))]), with a validation acc of: 0.8333333333333331\n",
      "The best MRMR (with 12 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model',\n",
      "                 GaussianProcessClassifier(kernel=RBF(length_scale=1) + WhiteKernel(noise_level=1)))]), with a validation acc of: 0.8999999999999999\n",
      "The best SFS (with 2 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model',\n",
      "                 GaussianProcessClassifier(kernel=RBF(length_scale=1) + WhiteKernel(noise_level=1)))]), with a validation acc of: 0.6\n"
     ]
    }
   ],
   "source": [
    "Y_ = Y.to_numpy(dtype='int')\n",
    "X_cbfs, X_mrmr, X_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF\n",
    "\n",
    "cv_folds = 6\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = GaussianProcessClassifier()\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "param_grid = [\n",
    "  {'ml_model__kernel': [DotProduct() + WhiteKernel(), DotProduct() + RBF(), RBF() + WhiteKernel(), DotProduct() + WhiteKernel() + RBF(),\n",
    "             DotProduct()*WhiteKernel(), DotProduct()*RBF(), WhiteKernel()*RBF(), RBF()*DotProduct() + WhiteKernel(),\n",
    "                       DotProduct()*WhiteKernel() + WhiteKernel()]},]\n",
    "\n",
    "param_lookup_cbfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_cbfs.fit(X_cbfs, Y_)\n",
    "best_model_cbfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "param_lookup_mrmr = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_mrmr.fit(X_mrmr, Y_)\n",
    "best_model_mrmr = param_lookup_mrmr.best_estimator_\n",
    "\n",
    "param_lookup_sfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_sfs.fit(X_sfs, Y_)\n",
    "best_model_sfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "scores_subset_cbfs = cross_val_score(best_model_cbfs, X_cbfs, Y_, cv=cv_folds)\n",
    "best_score_cbfs = np.mean(scores_subset_cbfs)\n",
    "\n",
    "scores_subset_mrmr = cross_val_score(best_model_mrmr, X_mrmr, Y_, cv=cv_folds)\n",
    "best_score_mrmr = np.mean(scores_subset_mrmr)\n",
    "\n",
    "scores_subset_sfs = cross_val_score(best_model_sfs, X_sfs, Y_, cv=cv_folds)\n",
    "best_score_sfs = np.mean(scores_subset_sfs)\n",
    "\n",
    "print(f'The best CBFS (with {len(features_cbfs)} features) model found is {best_model_cbfs}, with a validation acc of: {best_score_cbfs}')\n",
    "print(f'The best MRMR (with {len(features_mrmr)} features) model found is {best_model_mrmr}, with a validation acc of: {best_score_mrmr}')\n",
    "print(f'The best SFS (with {len(features_sfs)} features) model found is {best_model_sfs}, with a validation acc of: {best_score_sfs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained for the CBFS model is: 0.7142857142857143\n",
      "The test accuracy obtained for the MrMr model is: 0.5714285714285714\n",
      "The test accuracy obtained for the SFS model is: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(columns=['response'], inplace=False)\n",
    "Y_test = test_df['response'].to_numpy(dtype='int')\n",
    "\n",
    "X_train_cbfs, X_train_mrmr, X_train_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "Y_train = Y.to_numpy(dtype='int')\n",
    "\n",
    "best_model_cbfs = clone(best_model_cbfs)\n",
    "best_model_mrmr = clone(best_model_mrmr)\n",
    "best_model_sfs = clone(best_model_sfs)\n",
    "\n",
    "best_model_cbfs.fit(X_train_cbfs, Y_train)\n",
    "best_model_mrmr.fit(X_train_mrmr, Y_train)\n",
    "best_model_sfs.fit(X_train_sfs, Y_train)\n",
    "\n",
    "Y_pred_cbfs = best_model_cbfs.predict(X_test[features_cbfs].to_numpy())\n",
    "Y_pred_mrmr = best_model_mrmr.predict(X_test[features_mrmr].to_numpy())\n",
    "Y_pred_sfs = best_model_sfs.predict(X_test[features_sfs].to_numpy())\n",
    "\n",
    "cbfs_test_acc = accuracy_score(Y_test, Y_pred_cbfs)\n",
    "mrmr_test_acc = accuracy_score(Y_test, Y_pred_mrmr)\n",
    "sfs_test_acc = accuracy_score(Y_test, Y_pred_sfs)\n",
    "\n",
    "print(f'The test accuracy obtained for the CBFS model is: {cbfs_test_acc}')\n",
    "print(f'The test accuracy obtained for the MrMr model is: {mrmr_test_acc}')\n",
    "print(f'The test accuracy obtained for the SFS model is: {sfs_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 54.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 45.69it/s]\n"
     ]
    }
   ],
   "source": [
    "X = full_df.drop(columns=['response'], inplace=False)\n",
    "Y = full_df['response']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = KNeighborsClassifier()\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "features_cbfs = features_subset_cbfs.copy() \n",
    "\n",
    "results_mrmr = MrMr_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_mrmr = results_mrmr.iloc[0]['features']\n",
    "\n",
    "results_sfs = SFS_features_number_test(model=model, X=X, Y=Y, features_n_end=20, cv_folds=6)\n",
    "features_sfs = results_sfs.iloc[0]['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best CBFS (with 16 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model',\n",
      "                 KNeighborsClassifier(leaf_size=1, n_neighbors=9, p=1))]), with a validation acc of: 0.8333333333333331\n",
      "The best MRMR (with 5 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model',\n",
      "                 KNeighborsClassifier(leaf_size=1, n_neighbors=4, p=1))]), with a validation acc of: 0.8666666666666667\n",
      "The best SFS (with 9 features) model found is Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('ml_model',\n",
      "                 KNeighborsClassifier(leaf_size=1, n_neighbors=9, p=1))]), with a validation acc of: 0.5666666666666668\n"
     ]
    }
   ],
   "source": [
    "Y_ = Y.to_numpy(dtype='int')\n",
    "X_cbfs, X_mrmr, X_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF\n",
    "\n",
    "cv_folds = 6\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ml_model = KNeighborsClassifier()\n",
    "model = Pipeline(steps=[(\"scaler\", scaler), (\"ml_model\", ml_model)])\n",
    "\n",
    "param_grid = [\n",
    "  {'ml_model__leaf_size': list(range(1,50)), 'ml_model__n_neighbors': list(range(1,30)), 'ml_model__p': [1,2],},\n",
    " ]\n",
    "\n",
    "param_lookup_cbfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_cbfs.fit(X_cbfs, Y_)\n",
    "best_model_cbfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "param_lookup_mrmr = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_mrmr.fit(X_mrmr, Y_)\n",
    "best_model_mrmr = param_lookup_mrmr.best_estimator_\n",
    "\n",
    "param_lookup_sfs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_sfs.fit(X_sfs, Y_)\n",
    "best_model_sfs = param_lookup_cbfs.best_estimator_\n",
    "\n",
    "scores_subset_cbfs = cross_val_score(best_model_cbfs, X_cbfs, Y_, cv=cv_folds)\n",
    "best_score_cbfs = np.mean(scores_subset_cbfs)\n",
    "\n",
    "scores_subset_mrmr = cross_val_score(best_model_mrmr, X_mrmr, Y_, cv=cv_folds)\n",
    "best_score_mrmr = np.mean(scores_subset_mrmr)\n",
    "\n",
    "scores_subset_sfs = cross_val_score(best_model_sfs, X_sfs, Y_, cv=cv_folds)\n",
    "best_score_sfs = np.mean(scores_subset_sfs)\n",
    "\n",
    "print(f'The best CBFS (with {len(features_cbfs)} features) model found is {best_model_cbfs}, with a validation acc of: {best_score_cbfs}')\n",
    "print(f'The best MRMR (with {len(features_mrmr)} features) model found is {best_model_mrmr}, with a validation acc of: {best_score_mrmr}')\n",
    "print(f'The best SFS (with {len(features_sfs)} features) model found is {best_model_sfs}, with a validation acc of: {best_score_sfs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained for the CBFS model is: 0.8571428571428571\n",
      "The test accuracy obtained for the MrMr model is: 0.7142857142857143\n",
      "The test accuracy obtained for the SFS model is: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(columns=['response'], inplace=False)\n",
    "Y_test = test_df['response'].to_numpy(dtype='int')\n",
    "\n",
    "X_train_cbfs, X_train_mrmr, X_train_sfs = X[features_cbfs].to_numpy(), X[features_mrmr].to_numpy(), X[features_sfs].to_numpy()\n",
    "Y_train = Y.to_numpy(dtype='int')\n",
    "\n",
    "best_model_cbfs = clone(best_model_cbfs)\n",
    "best_model_mrmr = clone(best_model_mrmr)\n",
    "best_model_sfs = clone(best_model_sfs)\n",
    "\n",
    "best_model_cbfs.fit(X_train_cbfs, Y_train)\n",
    "best_model_mrmr.fit(X_train_mrmr, Y_train)\n",
    "best_model_sfs.fit(X_train_sfs, Y_train)\n",
    "\n",
    "Y_pred_cbfs = best_model_cbfs.predict(X_test[features_cbfs].to_numpy())\n",
    "Y_pred_mrmr = best_model_mrmr.predict(X_test[features_mrmr].to_numpy())\n",
    "Y_pred_sfs = best_model_sfs.predict(X_test[features_sfs].to_numpy())\n",
    "\n",
    "cbfs_test_acc = accuracy_score(Y_test, Y_pred_cbfs)\n",
    "mrmr_test_acc = accuracy_score(Y_test, Y_pred_mrmr)\n",
    "sfs_test_acc = accuracy_score(Y_test, Y_pred_sfs)\n",
    "\n",
    "print(f'The test accuracy obtained for the CBFS model is: {cbfs_test_acc}')\n",
    "print(f'The test accuracy obtained for the MrMr model is: {mrmr_test_acc}')\n",
    "print(f'The test accuracy obtained for the SFS model is: {sfs_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree\n",
    "\n",
    "The decision tree perform the feature selection by itself, so there is no need to use the feature selection criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best DT model found is Pipeline(steps=[('ml_model',\n",
      "                 DecisionTreeClassifier(max_depth=2, random_state=42))]), with a validation acc of: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "X = full_df.drop(columns=['response'], inplace=False)\n",
    "Y = full_df['response']\n",
    "\n",
    "Y_ = Y.to_numpy(dtype='int')\n",
    "#X_dt = X.copy()\n",
    "\n",
    "cv_folds = 6\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "ml_model = DecisionTreeClassifier(random_state=42)\n",
    "model = Pipeline(steps=[(\"ml_model\", ml_model)])\n",
    "\n",
    "max_depth = list(range(30)) + [None]\n",
    "min_samples_split=[1, 2]\n",
    "min_samples_leaf=[1, 2]\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "param_grid = [\n",
    "  {'ml_model__max_depth': max_depth, 'ml_model__min_samples_split': min_samples_split, 'ml_model__min_samples_leaf': min_samples_leaf,\n",
    "  'ml_model__criterion': criterion},\n",
    " ]\n",
    "\n",
    "param_lookup_dt = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_dt.fit(X, Y_)\n",
    "best_model_dt = param_lookup_dt.best_estimator_\n",
    "\n",
    "scores_subset_dt = cross_val_score(best_model_dt, X, Y_, cv=cv_folds)\n",
    "best_score_dt = np.mean(scores_subset_dt)\n",
    "\n",
    "print(f'The best DT model found is {best_model_dt}, with a validation acc of: {best_score_dt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained for the DT model is: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(columns=['response'], inplace=False)\n",
    "Y_test = test_df['response'].to_numpy(dtype='int')\n",
    "\n",
    "X_train_dt = X.to_numpy()\n",
    "Y_train = Y.to_numpy(dtype='int')\n",
    "\n",
    "best_model_dt = clone(best_model_dt)\n",
    "\n",
    "best_model_dt.fit(X_train_dt, Y_train)\n",
    "\n",
    "Y_pred_dt = best_model_dt.predict(X_test.to_numpy())\n",
    "\n",
    "dt_test_acc = accuracy_score(Y_test, Y_pred_dt)\n",
    "\n",
    "print(f'The test accuracy obtained for the DT model is: {dt_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best DT model found is Pipeline(steps=[('ml_model',\n",
      "                 RandomForestClassifier(max_depth=3, min_samples_leaf=2,\n",
      "                                        n_estimators=145, random_state=42))]), with a validation acc of: 0.7000000000000001\n"
     ]
    }
   ],
   "source": [
    "X = full_df.drop(columns=['response'], inplace=False)\n",
    "Y = full_df['response']\n",
    "\n",
    "Y_ = Y.to_numpy(dtype='int')\n",
    "\n",
    "cv_folds = 6\n",
    "\n",
    "ml_model = RandomForestClassifier(random_state=42)\n",
    "model = Pipeline(steps=[(\"ml_model\", ml_model)])\n",
    "\n",
    "max_depth = list(range(10)) + [None]\n",
    "min_samples_split=[1, 2]\n",
    "min_samples_leaf=[1, 2]\n",
    "criterion = ['gini']\n",
    "n_estimators = list(range(5, 166, 20))\n",
    "\n",
    "param_grid = [\n",
    "  {'ml_model__max_depth': max_depth, 'ml_model__min_samples_split': min_samples_split, 'ml_model__min_samples_leaf': min_samples_leaf,\n",
    "  'ml_model__criterion': criterion, 'ml_model__n_estimators': n_estimators},\n",
    " ]\n",
    "\n",
    "param_lookup_dt = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_dt.fit(X, Y_)\n",
    "best_model_dt = param_lookup_dt.best_estimator_\n",
    "\n",
    "scores_subset_dt = cross_val_score(best_model_dt, X, Y_, cv=cv_folds)\n",
    "best_score_dt = np.mean(scores_subset_dt)\n",
    "\n",
    "print(f'The best DT model found is {best_model_dt}, with a validation acc of: {best_score_dt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained for the Random Forest model is: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(columns=['response'], inplace=False)\n",
    "Y_test = test_df['response'].to_numpy(dtype='int')\n",
    "\n",
    "X_train_dt = X.to_numpy()\n",
    "Y_train = Y.to_numpy(dtype='int')\n",
    "\n",
    "best_model_dt = clone(best_model_dt)\n",
    "\n",
    "best_model_dt.fit(X_train_dt, Y_train)\n",
    "\n",
    "Y_pred_dt = best_model_dt.predict(X_test.to_numpy())\n",
    "\n",
    "dt_test_acc = accuracy_score(Y_test, Y_pred_cbfs)\n",
    "\n",
    "print(f'The test accuracy obtained for the Random Forest model is: {dt_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best DT model found is Pipeline(steps=[('ml_model',\n",
      "                 AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2,\n",
      "                                                                          random_state=42),\n",
      "                                    learning_rate=2, n_estimators=5,\n",
      "                                    random_state=42))]), with a validation acc of: 0.7000000000000001\n"
     ]
    }
   ],
   "source": [
    "X = full_df.drop(columns=['response'], inplace=False)\n",
    "Y = full_df['response']\n",
    "\n",
    "Y_ = Y.to_numpy(dtype='int')\n",
    "\n",
    "cv_folds = 6\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "ml_model = AdaBoostClassifier(base_estimator=base_estimator, random_state=42)\n",
    "model = Pipeline(steps=[(\"ml_model\", ml_model)])\n",
    "\n",
    "learning_rate = list(range(1, 11, 1))\n",
    "n_estimators = list(range(5, 166, 20))\n",
    "\n",
    "param_grid = [\n",
    "  {'ml_model__n_estimators': n_estimators, 'ml_model__learning_rate':learning_rate}\n",
    " ]\n",
    "param_lookup_dt = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv_folds)\n",
    "param_lookup_dt.fit(X, Y_)\n",
    "best_model_dt = param_lookup_dt.best_estimator_\n",
    "\n",
    "scores_subset_dt = cross_val_score(best_model_dt, X, Y_, cv=cv_folds)\n",
    "best_score_dt = np.mean(scores_subset_dt)\n",
    "\n",
    "print(f'The best DT model found is {best_model_dt}, with a validation acc of: {best_score_dt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy obtained for the AdaBoost model is: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(columns=['response'], inplace=False)\n",
    "Y_test = test_df['response'].to_numpy(dtype='int')\n",
    "\n",
    "X_train_dt = X.to_numpy()\n",
    "Y_train = Y.to_numpy(dtype='int')\n",
    "\n",
    "best_model_dt = clone(best_model_dt)\n",
    "\n",
    "best_model_dt.fit(X_train_dt, Y_train)\n",
    "\n",
    "Y_pred_dt = best_model_dt.predict(X_test.to_numpy())\n",
    "\n",
    "dt_test_acc = accuracy_score(Y_test, Y_pred_cbfs)\n",
    "\n",
    "print(f'The test accuracy obtained for the AdaBoost model is: {dt_test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
